---
layout:     post
title:      "反爬战斗之随机User-Agent请求头 fake_useragent 模块的使用 和 各种请求报错解决"
subtitle:   
date:       2019-10-21
author:     Mehaei
thumbnail:  /images/7913a937/thumbnail.png
catalog: true
categories: 爬虫之路
original_url: https://mp.weixin.qq.com/s/32sLM9sb190M63czy8tFxA
tags:
    - 爬虫之路
---

反爬战斗系列从今天就会不断更新内容了, 还有每日一技系列

不能在堕落下去了

加油

在爬虫中, 最基础的反爬就是 User-Agent 请求头,但是也不能手动写出那么多真实的请求头呀, 这时候就要用上神奇的fake\_useragent模块了

那么接下来就简单讲讲这个fake\_useragent模块

文档地址: https://pypi.org/project/fake-useragent/

它可以返回各种浏览器的各个版本的请求头, 主流的firefox, chrome, safariden等等

安装

```
pip3 install fake_useragent
```

使用

```
from fake_useragent import UserAgent
ua = UserAgent()
#  随机返回请求头
print(ua.random)
# 随机返回ie请求头
print(u.ie)
# 随机返回chrom请求头
print(u.chrome)
```

# 但由于本地网络等各种原因, 无法获取请求头

根本的解决办法就是 : 把所有的请求头保存到本地

为了方便以后使用, 我已经整理好了几份不同格式的请求头, 代码已放到GitHub

**https://github.com/Mehaei/local\_ua**

使用, 这里就写了一个方法, 可以无限扩展功能

```
from user_agent import UserAgent
# 获取所有浏览器的随机请求头
ua = UserAgent()
ua.rget

# 获取chrome随机请求头
ua = UserAgent("chrome")
ua.rget
```

如有错误, 欢迎交流